"""
Newspaper


Несколько лет назад мне активно пришлось работать с извлечением текстов статей из разных сайтов. Задача несложная —
получи ссылку на документ, выкачай HTML разметку, обработай ее парсером по типу beautiful soup — и вот тебе вся нужная
информация. Минус в этом всем один — если сайтов много и все они разные, то работа программиста сводится к откровенно
обезьяньему труду — ковырянии в HTML страниц и написании абсолютно однообразных парсеров по извлечению осмысленного
контента.


На второй день возни с процессорами разметки и описания селекторов тегов я начал тихонько сходить с ума и задумался
об автоматической потрошилке верстки. На глаза мне попалась либа newspaper.


Эта либа автоматически извлекает полезную инфу из новостей, журнальных и блоговых статей и прочих сайтов, где основной
контент — это большие блоки текста. Библиотека сама анализирует страницы несложным алгоритмом, находит в коде
осмысленный текст и извлекает его — вам вообще не потребуется описывать правила парсинга!


Автоматические извлечение текста статьи их страницы
Извлечение заглавной картинки поста
Полное извлечение всех картинок, ключевых слов и метаданных (автор, время публикации)

"""

from newspaper import Article

url = 'http://fox13now.com/2013/12/30/new-year-new-laws-obamacare-pot-guns-and-drones/'
article = Article(url)
article.download()

#Скачали текст и запустил парсинг
article.parse()

article.authors
# ['Leigh Ann Caldwell', 'John Honway']

article.publish_date
# datetime.datetime(2013, 12, 30, 0, 0)

# А вот тут лежит уже добытый текст! Все достается само, парсить ничего не надо
article.text
# 'Washington (CNN) -- Not everyone subscribes to a New Year's resolution...'

article.top_image
# 'http://someCDN.com/blah/blah/blah/file.png'

article.movies
# ['http://youtube.com/path/to/link.com', ...]
